{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55a2bf3d",
   "metadata": {},
   "source": [
    "# Master Script: HAPI Prediction Pipeline (RF + XGBoost + SHAP)\n",
    "\n",
    "## Overview\n",
    "This is the Master Script for the \"Beyond Braden\" project. It consolidates the entire analytic pipeline into a single execution flow. It takes the final merged clinical dataset and performs cleaning, leakage detection, model training, evaluation, and patient risk stratification.\n",
    "\n",
    "## Features\n",
    "1.  **Automated Leakage Detection:** * Scans all features for correlation $> 0.95$ with the target.\n",
    "    * Automatically drops \"future\" columns (e.g., *Length of Stay*, *Wound Vac usage*) to ensure the model predicts risk rather than confirming a diagnosis.\n",
    "2.  **Model Competition:** * Trains a **Random Forest** (Baseline).\n",
    "    * Trains an **XGBoost** classifier (Advanced).\n",
    "3.  **Explainable AI (SHAP):** generates Beeswarm and Bar plots to explain *why* the model flags specific patients.\n",
    "4.  **Clinical Decision Support:** Outputs a prioritized list of \"High Risk\" patients for clinical review.\n",
    "\n",
    "## Requirements\n",
    "* **Python 3.8+**\n",
    "* **Libraries:** `pandas`, `numpy`, `scikit-learn`, `xgboost`, `shap`, `matplotlib`, `seaborn`\n",
    "\n",
    "```bash\n",
    "pip install scikit-learn xgboost shap pandas matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e909a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    accuracy_score\n",
    ")\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee39ea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    accuracy_score\n",
    ")\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94f71fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure\n",
    "# Path to the final merged analytic dataset (created in previous steps)\n",
    "DATA_PATH = r\"D:\\School\\5141\\FINAL_HAPI_ANALYTIC.csv\"\n",
    "\n",
    "# The binary target variable (1 = HAPI, 0 = No HAPI)\n",
    "TARGET_COL = \"HAPI_FINAL\"\n",
    "\n",
    "# Output directory for PNGs, CSVs, and risk tables\n",
    "OUTPUT_DIR = r\"D:\\School\\5141\\model_outputs\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d7a4236a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning and Leakage Prevention\n",
    "# These columns contain information that happens AFTER the outcome or are proxy labels.\n",
    "# We must drop them to prevent Data Leakage.\n",
    "\n",
    "BAD_COLUMNS = [\n",
    "    # Direct labels or synonymous outcomes\n",
    "    \"HAPI_STRUCTURED\",\n",
    "    \"HAPI_UNSTRUCTURED\",\n",
    "    \"has_HAPI\",\n",
    "    \"notes_pu\",\n",
    "    \n",
    "    # Treatment that happens after a HAPI develops\n",
    "    \"has_wound_vac\",\n",
    "    \"first_wound_note_time\",\n",
    "\n",
    "    # Time-dependent variables\n",
    "    # LOS is often longer *because* they got a HAPI, not the cause.\n",
    "    \"LOS_DAYS\",\n",
    "    \"LOS_HOURS\",\n",
    "    \"hours_after_admit\",\n",
    "\n",
    "    # Summary stats that aggregate the entire stay \n",
    "    \"num_distinct_drugs\",\n",
    "    \"num_distinct_pharm_meds\",\n",
    "    \"num_pharm_orders\",\n",
    "    \"total_meds_orders\",\n",
    "    \"num_prescriptions\",\n",
    "    \"num_high_risk_drugs\",\n",
    "    \"num_high_risk_pharm_orders\",\n",
    "    \"has_sedation_drug\",\n",
    "    \"has_high_risk_drug\",\n",
    "    \"has_high_risk_pharm_order\",\n",
    "\n",
    "    # ICU procedures over entire stay\n",
    "    \"had_icu_procedure\",\n",
    "    \"had_icu_procedure_0_24h\",\n",
    "    \"had_icu_procedure_0_48h\",\n",
    "    \"num_icu_procedures_0_24h\",\n",
    "    \"num_icu_procedures_0_48h\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ea0c367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels \n",
    "# These columns contain information that happens after the outcome or are proxy labels.\n",
    "# We must drop them to prevent \"Data Leakage.\"\n",
    "\n",
    "BAD_COLUMNS = [\n",
    "    # Direct labels or synonymous outcomes\n",
    "    \"HAPI_STRUCTURED\",\n",
    "    \"HAPI_UNSTRUCTURED\",\n",
    "    \"has_HAPI\",\n",
    "    \"notes_pu\",\n",
    "    \n",
    "    # Treatment that happens *after* a HAPI develops\n",
    "    \"has_wound_vac\",\n",
    "    \"first_wound_note_time\",\n",
    "\n",
    "    # Time-dependent variables (Post-Outcome Info)\n",
    "    # LOS is often longer *because* they got a HAPI, not the cause.\n",
    "    \"LOS_DAYS\",\n",
    "    \"LOS_HOURS\",\n",
    "    \"hours_after_admit\",\n",
    "\n",
    "    # Summary stats that aggregate the *entire* stay (Future info)\n",
    "    \"num_distinct_drugs\",\n",
    "    \"num_distinct_pharm_meds\",\n",
    "    \"num_pharm_orders\",\n",
    "    \"total_meds_orders\",\n",
    "    \"num_prescriptions\",\n",
    "    \"num_high_risk_drugs\",\n",
    "    \"num_high_risk_pharm_orders\",\n",
    "    \"has_sedation_drug\",\n",
    "    \"has_high_risk_drug\",\n",
    "    \"has_high_risk_pharm_order\",\n",
    "\n",
    "    # ICU procedures over entire stay\n",
    "    \"had_icu_procedure\",\n",
    "    \"had_icu_procedure_0_24h\",\n",
    "    \"had_icu_procedure_0_48h\",\n",
    "    \"num_icu_procedures_0_24h\",\n",
    "    \"num_icu_procedures_0_48h\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "763aadb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization Labels \n",
    "# Mapping column names to clean, human-readable labels for charts.\n",
    "FEATURE_LABELS = {\n",
    "    \"age\": \"Age\",\n",
    "    \"anchor_age\": \"Age at Admission\",\n",
    "    \"gender_F\": \"Female Gender\",\n",
    "    \"gender_M\": \"Male Gender\",\n",
    "    \"bmi\": \"Body Mass Index\",\n",
    "    \"icu_stay\": \"ICU Stay Indicator (Early)\",\n",
    "    \"icu_hours_0_48h\": \"ICU Hours (First 48h)\",\n",
    "    \"num_lab_events_0_48h\": \"Lab Events (First 48h)\",\n",
    "    \"avg_heart_rate_0_48h\": \"Average Heart Rate (First 48h)\",\n",
    "    \"min_map_0_48h\": \"Lowest MAP (First 48h)\",\n",
    "    \"max_map_0_48h\": \"Highest MAP (First 48h)\",\n",
    "    \"avg_resp_rate_0_48h\": \"Average Respiratory Rate (First 48h)\",\n",
    "    \"avg_temp_0_48h\": \"Average Temperature (First 48h)\",\n",
    "    \"avg_spo2_0_48h\": \"Average SpOâ‚‚ (First 48h)\",\n",
    "    \"num_procedures\": \"Number of Procedures\",\n",
    "    \"num_med_admins_0_48h\": \"Medication Administrations (First 48h)\",\n",
    "    \"creatinine_first\": \"Creatinine (First Lab)\",\n",
    "    \"glucose_first\": \"Glucose (First Lab)\",\n",
    "    \"albumin_first\": \"Albumin (First Lab)\",\n",
    "    \"gcs_total_0_24h\": \"GCS Total (First 24h)\",\n",
    "    \"rrt\": \"Renal Replacement Therapy\",\n",
    "    \"num_ed_visits_lastyear\": \"ED Visits (Last Year)\",\n",
    "    \"num_admissions_lastyear\": \"Admissions (Last Year)\",\n",
    "}\n",
    "\n",
    "def label_feature(name: str) :\n",
    "    return FEATURE_LABELS.get(name, name.replace(\"_\", \" \").title())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "02c5eba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_leakage(X: pd.DataFrame, y: pd.Series, threshold: float = 0.95):\n",
    "    \"\"\"\n",
    "    Scans for features that are statistically too similar to the target.\n",
    "    If correlation > 0.95, it's likely a proxy for the label (Leakage).\n",
    "    \"\"\"\n",
    "    y_numeric = y.astype(float).values\n",
    "    leaky_cols = []\n",
    "\n",
    "    for col in X.columns:\n",
    "        col_values = X[col].values.astype(float)\n",
    "        if np.std(col_values) == 0: continue # Skip constant columns\n",
    "        \n",
    "        corr = np.corrcoef(col_values, y_numeric)[0, 1]\n",
    "        if np.isnan(corr): continue\n",
    "        \n",
    "        if abs(corr) >= threshold:\n",
    "            leaky_cols.append((col, corr))\n",
    "\n",
    "    if leaky_cols:\n",
    "        for col, corr in leaky_cols:\n",
    "            print(f\"   - {col}: correlation = {corr:.3f}\")\n",
    "        X = X.drop(columns=[c for c, _ in leaky_cols])\n",
    "    else:\n",
    "        print(\"No additional high-correlation leakage detected.\")\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a94afa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path: str, target_col: str):\n",
    "    \"\"\"\n",
    "    Master data loader. Performs data cleaning process:\n",
    "    1. Load CSV\n",
    "    2. Drop ID columns\n",
    "    3. Drop known 'BAD_COLUMNS' (defined above)\n",
    "    4. Drop non-numeric data\n",
    "    5. Fill NaNs\n",
    "    6. Drop columns that match the target exactly\n",
    "    7. Run statistical leakage check\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"CSV not found at: {path}\")\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    if target_col not in df.columns:\n",
    "        raise ValueError(f\"Target column '{target_col}' not found.\")\n",
    "\n",
    "    y = df[target_col].astype(int)\n",
    "\n",
    "    # Drop IDs, Target, and Known Bad Columns\n",
    "    drop_cols = [\"hadm_id\", \"subject_id\", target_col]\n",
    "    \n",
    "    # Drop columns with suspicious names \n",
    "    leak_patterns = [\"HAPI\", \"ULCER\", \"PRESSURE_ULCER\", \"PU_LABEL\", \"WOUND\"]\n",
    "    for col in df.columns:\n",
    "        upper = col.upper()\n",
    "        if any(pat in upper for pat in leak_patterns) and col != target_col:\n",
    "            drop_cols.append(col)\n",
    "\n",
    "    drop_cols.extend(BAD_COLUMNS)\n",
    "    \n",
    "    # Intersect with actual columns to avoid errors\n",
    "    drop_cols = list(set(c for c in drop_cols if c in df.columns))\n",
    "    print(f\"Dropping {len(drop_cols)} columns (IDs, Target, Leakage).\")\n",
    "    X = df.drop(columns=drop_cols)\n",
    "\n",
    "    # Drop non-numeric (Text/Dates)\n",
    "    non_numeric = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "    if non_numeric:\n",
    "        print(f\"Dropping non-numeric columns: {non_numeric}\")\n",
    "        X = X.drop(columns=non_numeric)\n",
    "\n",
    "    # Fill Missing Values (0 is standard for counts/flags)\n",
    "    X = X.fillna(0)\n",
    "\n",
    "    # Drop \"Perfect Predictors\" (Columns that are exactly the label)\n",
    "    leaky_exact = []\n",
    "    for col in X.columns:\n",
    "        if X[col].nunique() <= 5:\n",
    "            if (X[col] == y).all() or (X[col] == 1 - y).all():\n",
    "                leaky_exact.append(col)\n",
    "    \n",
    "    if leaky_exact:\n",
    "        print(f\"Dropping exact label duplicates: {leaky_exact}\")\n",
    "        X = X.drop(columns=leaky_exact)\n",
    "\n",
    "    # Statistical Leakage Check\n",
    "    X = remove_leakage(X, y, threshold=0.95)\n",
    "\n",
    "    print(f\"\\nFinal Dataset: {X.shape[0]} rows, {X.shape[1]} features.\")\n",
    "    print(\"Class Balance (Target):\")\n",
    "    print(y.value_counts(normalize=True).rename(\"proportion\"))\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ae26ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_name, y_true, y_pred, y_prob):\n",
    "    \"\"\"Generates a DataFrame row of metrics (Precision, Recall, F1, AUC).\"\"\"\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    rows = []\n",
    "    for label, stats in report.items():\n",
    "        if isinstance(stats, dict):\n",
    "            rows.append({\n",
    "                \"model\": model_name,\n",
    "                \"label\": label,\n",
    "                \"precision\": stats.get(\"precision\", np.nan),\n",
    "                \"recall\": stats.get(\"recall\", np.nan),\n",
    "                \"f1\": stats.get(\"f1-score\", np.nan),\n",
    "                \"support\": stats.get(\"support\", np.nan),\n",
    "                \"roc_auc\": auc,\n",
    "                \"accuracy\": acc,\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def confusion_matrix_output(y_true, y_pred, title, save_path=None, normalize=False):\n",
    "    \"\"\"Plots a standard Seaborn heatmap for the confusion matrix.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    if normalize:\n",
    "        cm = cm.astype(\"float\") / cm.sum(axis=1, keepdims=True)\n",
    "        fmt = \".2f\"\n",
    "    else:\n",
    "        fmt = \"d\"\n",
    "\n",
    "    labels = [\"No HAPI\", \"HAPI\"]\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=fmt, cmap=\"rocket\", xticklabels=labels, yticklabels=labels, cbar=False)\n",
    "    plt.title(title)\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        print(f\"Saved plot: {save_path}\")\n",
    "    plt.close()\n",
    "\n",
    "def humanize_text(importances: pd.Series, title: str, filename: str):\n",
    "    \"\"\"\n",
    "    Maps raw feature names to human-readable labels using FEATURE_LABELS\n",
    "    and saves a horizontal bar chart.\n",
    "    \"\"\"\n",
    "    top20 = importances.head(20)\n",
    "    pretty_index = [label_feature(col) for col in top20.index]\n",
    "    pretty_series = pd.Series(top20.values, index=pretty_index)\n",
    "\n",
    "    print(f\"\\n{title} (Top 5):\")\n",
    "    print(pretty_series.head(5).to_string())\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    # Invert so top feature is at the top of the chart\n",
    "    pretty_series.iloc[::-1].plot(kind=\"barh\", color='skyblue', edgecolor='black')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Importance Score\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, filename), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "def summarize_patient_risk(model, X_subset, y_subset=None, model_name=\"Model\", top_n=10):\n",
    "    \"\"\"\n",
    "    Generates a Clinical Risk List. \n",
    "    Returns the top N patients most likely to have HAPI based on the model.\n",
    "    \"\"\"\n",
    "    probs = model.predict_proba(X_subset)[:, 1]\n",
    "    \n",
    "    df = pd.DataFrame({\"predicted_risk\": probs}, index=X_subset.index)\n",
    "    if y_subset is not None:\n",
    "        df[\"true_label\"] = y_subset\n",
    "\n",
    "    # Risk Stratification \n",
    "    def bucket(p):\n",
    "        if p >= 0.40: return \"HIGH\"\n",
    "        elif p >= 0.20: return \"MEDIUM\"\n",
    "        else: return \"LOW\"\n",
    "\n",
    "    df[\"risk_bucket\"] = df[\"predicted_risk\"].apply(bucket)\n",
    "    df_sorted = df.sort_values(\"predicted_risk\", ascending=False).head(top_n)\n",
    "\n",
    "    print(f\"\\n--- Top {top_n} High-Risk Patients ({model_name}) ---\")\n",
    "    print(df_sorted)\n",
    "    return df_sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "67385b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 26 columns (IDs, Target, Leakage).\n",
      "Dropping non-numeric columns: ['admittime']\n",
      "No additional high-correlation leakage detected.\n",
      "\n",
      "Final Dataset: 555244 rows, 61 features.\n",
      "Class Balance (Target):\n",
      "HAPI_FINAL\n",
      "0    0.744428\n",
      "1    0.255572\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Train shape: (444195, 61) | Test shape: (111049, 61)\n",
      "\n",
      "------------------------------------------------------------\n",
      "TRAINING: Random Forest (Baseline)\n",
      "------------------------------------------------------------\n",
      "\n",
      "Random Forest Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87     82668\n",
      "           1       0.62      0.53      0.57     28381\n",
      "\n",
      "    accuracy                           0.80    111049\n",
      "   macro avg       0.74      0.71      0.72    111049\n",
      "weighted avg       0.79      0.80      0.79    111049\n",
      "\n",
      "Saved plot: D:\\School\\5141\\model_outputs\\rf_confusion_matrix.png\n",
      "\n",
      "Top 20 Features - Random Forest (Top 5):\n",
      "Num Detail Items     0.143332\n",
      "Age                  0.142645\n",
      "Total Meds Admin     0.064197\n",
      "Num Meds Admin       0.062122\n",
      "Num Distinct Meds    0.047479\n",
      "\n",
      "------------------------------------------------------------\n",
      "TRAINING: XGBoost (Gradient Boosting)\n",
      "------------------------------------------------------------\n",
      "\n",
      "XGBoost Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87     82668\n",
      "           1       0.65      0.49      0.56     28381\n",
      "\n",
      "    accuracy                           0.80    111049\n",
      "   macro avg       0.75      0.70      0.72    111049\n",
      "weighted avg       0.79      0.80      0.79    111049\n",
      "\n",
      "Saved plot: D:\\School\\5141\\model_outputs\\xgb_confusion_matrix.png\n",
      "\n",
      "Top 20 Features - XGBoost (Top 5):\n",
      "Immobility                    0.094289\n",
      "Num Detail Items              0.089903\n",
      "Num Meds Admin                0.066462\n",
      "Sedation Ordered Not Admin    0.061122\n",
      "Perfusion Poor                0.060261\n",
      "\n",
      "------------------------------------------------------------\n",
      "EXPLAINABILITY: Computing SHAP Values\n",
      "------------------------------------------------------------\n",
      "   > SHAP plots saved to D:\\School\\5141\\model_outputs\n",
      "\n",
      "--- Top 10 High-Risk Patients (XGBoost) ---\n",
      "        predicted_risk  true_label risk_bucket\n",
      "287395        0.978065           1        HIGH\n",
      "137528        0.973398           1        HIGH\n",
      "171371        0.972929           1        HIGH\n",
      "173265        0.970308           1        HIGH\n",
      "171369        0.970081           1        HIGH\n",
      "69221         0.968026           1        HIGH\n",
      "508487        0.966773           1        HIGH\n",
      "385732        0.961849           1        HIGH\n",
      "9728          0.960993           1        HIGH\n",
      "116213        0.960267           1        HIGH\n",
      "\n",
      "Pipeline Complete. All outputs saved to: D:\\School\\5141\\model_outputs\n"
     ]
    }
   ],
   "source": [
    "#Execute\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Load Data    \n",
    "    X, y = load_data(DATA_PATH, TARGET_COL)\n",
    "    \n",
    "    # Stratified split to ensure HAPI cases are distributed evenly\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    print(f\"\\nTrain shape: {X_train.shape} | Test shape: {X_test.shape}\")\n",
    "\n",
    "    all_metrics = []\n",
    "\n",
    "    # Basline Model: Random Forest\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"TRAINING: Random Forest (Baseline)\")\n",
    "    print(\"-\"*60)\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=None,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        class_weight=None \n",
    "    )\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    rf_pred = rf.predict(X_test)\n",
    "    rf_prob = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Evaluate\n",
    "    print(\"\\nRandom Forest Report:\")\n",
    "    print(classification_report(y_test, rf_pred))\n",
    "    all_metrics.append(evaluate_model(\"RandomForest\", y_test, rf_pred, rf_prob))\n",
    "\n",
    "    # Save Confusion Matrix\n",
    "    confusion_matrix_output(\n",
    "        y_test, rf_pred, \n",
    "        title=\"Random Forest - Confusion Matrix\",\n",
    "        save_path=os.path.join(OUTPUT_DIR, \"rf_confusion_matrix.png\"),\n",
    "        normalize=True\n",
    "    )\n",
    "    \n",
    "    # Feature Importance \n",
    "    rf_imps = pd.Series(rf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "    humanize_text(rf_imps, \"Top 20 Features - Random Forest\", \"rf_top20_features.png\")\n",
    "\n",
    "\n",
    "    # Model: XGBOOST\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"TRAINING: XGBoost (Gradient Boosting)\")\n",
    "    print(\"-\"*60)\n",
    "    xgb = XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        tree_method=\"hist\", \n",
    "        eval_metric=\"auc\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    xgb.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    xgb_pred = xgb.predict(X_test)\n",
    "    xgb_prob = xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Evaluate\n",
    "    print(\"\\nXGBoost Report:\")\n",
    "    print(classification_report(y_test, xgb_pred))\n",
    "    all_metrics.append(evaluate_model(\"XGBoost\", y_test, xgb_pred, xgb_prob))\n",
    "\n",
    "    # Save Confusion Matrix\n",
    "    confusion_matrix_output(\n",
    "        y_test, xgb_pred, \n",
    "        title=\"XGBoost - Confusion Matrix\",\n",
    "        save_path=os.path.join(OUTPUT_DIR, \"xgb_confusion_matrix.png\"),\n",
    "        normalize=True\n",
    "    )\n",
    "\n",
    "    # Feature Importance (XGB)\n",
    "    xgb_imps = pd.Series(xgb.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "    humanize_text(xgb_imps, \"Top 20 Features - XGBoost\", \"xgb_top20_features.png\")\n",
    "\n",
    "\n",
    "    # SHAP ANALYSIS: explains why the model made specific decisions.\n",
    "    # It takes a sample of the test set to speed up calculation.\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"EXPLAINABILITY: Computing SHAP Values\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    shap_sample = X_test.sample(n=2000, random_state=42) if len(X_test) > 2000 else X_test\n",
    "    explainer = shap.TreeExplainer(xgb)\n",
    "    shap_values = explainer.shap_values(shap_sample)\n",
    "\n",
    "    # Bar Plot \n",
    "    plt.figure()\n",
    "    shap.summary_plot(shap_values, shap_sample, plot_type=\"bar\", max_display=20, show=False)\n",
    "    plt.title(\"SHAP Feature Importance (XGBoost)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, \"xgb_shap_bar.png\"), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Beeswarm Plot \n",
    "    plt.figure()\n",
    "    shap.summary_plot(shap_values, shap_sample, max_display=20, show=False)\n",
    "    plt.title(\"SHAP Beeswarm Summary (XGBoost)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, \"xgb_shap_beeswarm.png\"), dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"   > SHAP plots saved to {OUTPUT_DIR}\")\n",
    "\n",
    "\n",
    "    # Patient Risk Stratification\n",
    "    # Identify specific patients who need intervention\n",
    "    _ = summarize_patient_risk(xgb, X_test, y_test, model_name=\"XGBoost\", top_n=10)\n",
    "\n",
    "    # Save Results\n",
    "    metrics_df = pd.concat(all_metrics, ignore_index=True)\n",
    "    metrics_path = os.path.join(OUTPUT_DIR, \"model_comparison_metrics.csv\")\n",
    "    metrics_df.to_csv(metrics_path, index=False)\n",
    "    \n",
    "    print(f\"\\nPipeline Complete. All outputs saved to: {OUTPUT_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
