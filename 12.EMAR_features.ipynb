{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cd0edf4",
   "metadata": {},
   "source": [
    "# EMAR Feature Extraction & Risk Factor Analysis\n",
    "\n",
    "## Description\n",
    "This script processes the Electronic Medication Administration Record (EMAR) from MIMIC-IV to engineer features related to pharmacological risk factors for Hospital-Acquired Pressure Injuries (HAPI).\n",
    "\n",
    "## Clinical Justification\n",
    "Medications are a critical proxy for patient physiological state and immobility levels, directly mapping to the Braden Scale sub-categories:\n",
    "* **Perfusion (Tissue Tolerance):** \"Vasoactive Agents\" (e.g., Norepinephrine, Dopamine) cause peripheral vasoconstriction, reducing blood flow to skin and increasing ischemia risk.\n",
    "* **Sensory Perception:** \"Sedatives\" (e.g., Propofol, Versed) reduce a patient's ability to feel pressure or pain.\n",
    "* **Mobility/Activity:** \"Opioids\" and Sedatives depress the central nervous system, reducing spontaneous body movement and repositioning.\n",
    "\n",
    "## Inputs & Outputs\n",
    "* **Input:** `emar.csv` (Linking admission IDs to medication events)\n",
    "* **Input:** `emar_detail.csv` (Detailed drug names and administration info)\n",
    "* **Output:** `emar_feat.csv` (Aggregated medication features per admission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69083367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c3981eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "BASE_DIR = r\"D:\\School\\5141\"\n",
    "\n",
    "EMAR_PATH        = os.path.join(BASE_DIR, \"emar.csv\", \"emar.csv\")\n",
    "EMAR_DETAIL_PATH = os.path.join(BASE_DIR, \"emar_detail.csv\", \"emar_detail.csv\")\n",
    "OUTPUT_PATH      = os.path.join(BASE_DIR, \"emar_feat.csv\")\n",
    "\n",
    "# Chunk size for reading emar_detail\n",
    "CHUNKSIZE = 500_000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e85f748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# High-risk medication classes.\n",
    "\n",
    "# GENERAL HIGH RISK\n",
    "# Combined list of all drugs known to impact perfusion or mobility.\n",
    "HIGH_RISK_MED_KEYWORDS = [\n",
    "    \"norepinephrine\", \"levophed\", \"epinephrine\", \"vasopressin\",\n",
    "    \"dopamine\", \"dobutamine\", \"phenylephrine\", \"neosynephrine\",\n",
    "    \"propofol\", \"midazolam\", \"versed\", \"lorazepam\", \"ativan\",\n",
    "    \"dexmedetomidine\", \"precedex\",\n",
    "    \"fentanyl\", \"morphine\", \"hydromorphone\", \"dilaudid\", \"oxycodone\"\n",
    "]\n",
    "\n",
    "# VASOACTIVE AGENTS\n",
    "# Peripheral Vasoconstriction leads to Ischemia.\n",
    "VASOACTIVE_KEYWORDS = [\n",
    "    \"norepinephrine\", \"levophed\", \"epinephrine\", \"vasopressin\",\n",
    "    \"dopamine\", \"dobutamine\", \"phenylephrine\", \"neosynephrine\"\n",
    "]\n",
    "\n",
    "# SEDATIVES\n",
    "# Immobility & Sensory Loss: Patients on these drips cannot move to relieve pressure.\n",
    "SEDATION_KEYWORDS = [\n",
    "    \"propofol\", \"midazolam\", \"versed\", \"lorazepam\", \"ativan\",\n",
    "    \"dexmedetomidine\", \"precedex\"\n",
    "]\n",
    "\n",
    "# OPIOIDS\n",
    "# CNS Depression: Reduces spontaneous movement during sleep/rest.\n",
    "OPIOID_KEYWORDS = [\n",
    "    \"fentanyl\", \"morphine\", \"hydromorphone\", \"dilaudid\", \"oxycodone\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af815c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loader Functions\n",
    "def load_emar(path: str):\n",
    "    \"\"\"\n",
    "    Loads the base EMAR linking table with strict memory optimization.\n",
    "    \n",
    "    Operations:\n",
    "    1. Reads only the 'emar_id' and 'hadm_id' columns from the massive CSV.\n",
    "    2. Drops rows where 'hadm_id' is missing (useless for our analysis).\n",
    "    3. Casts 'hadm_id' to Int64 to allow clean merging.\n",
    "    \n",
    "    Args:\n",
    "        path (str): The file path to `emar.csv`.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A lookup table mapping Medication IDs to Admission IDs.\n",
    "    \"\"\"\n",
    "    # 1. Check columns first\n",
    "    header = pd.read_csv(path, nrows=0)\n",
    "    cols = set(header.columns)\n",
    "    \n",
    "    use_cols = [\"emar_id\", \"hadm_id\"]\n",
    "    if \"subject_id\" in cols:\n",
    "        use_cols.append(\"subject_id\")\n",
    "        \n",
    "    # 2. Read ONLY needed columns\n",
    "    df = pd.read_csv(path, usecols=use_cols, low_memory=False)\n",
    "\n",
    "    # 3. Drop rows with no admission ID immediately\n",
    "    df = df.dropna(subset=[\"hadm_id\"])\n",
    "    df[\"hadm_id\"] = df[\"hadm_id\"].astype(\"Int64\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def detect_emar_detail_text_col(path: str):\n",
    "    \"\"\"\n",
    "    Identifies the column containing drug names in the detail file.\n",
    "    \n",
    "    Operations:\n",
    "    1. Reads a small sample (1000 rows) of the detail file.\n",
    "    2. Iterates through a list of known possible column names.\n",
    "    3. Returns the first match found.\n",
    "    \n",
    "    Arguments:\n",
    "        path (str): The file path to `emar_detail.csv`.\n",
    "        \n",
    "    Returns:\n",
    "        str: The name of the column containing medication text.\n",
    "    \"\"\"\n",
    "\n",
    "    sample = pd.read_csv(path, low_memory=False, nrows=1000)\n",
    "    \n",
    "    candidates = [\"product_description\", \"medication\", \"drug_name\"]\n",
    "    for c in candidates:\n",
    "        if c in sample.columns:\n",
    "            print(f\"Using text column: {c}\")\n",
    "            return c\n",
    "    raise ValueError(\"Could not find medication text column in emar_detail.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e4d409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuck processing function\n",
    "def build_emar_features_chunked(emar, detail_path, text_col, chunksize):\n",
    "    \"\"\"\n",
    "    Processes the massive EMAR detail file in chunks to extract clinical features.\n",
    "    \n",
    "    Operations:\n",
    "    1. Iterates through emar_detail.csv`in chunks of chunksize rows.\n",
    "    2. Merges each chunk with ema` to attach the Admission ID (hadm_id).\n",
    "    3. Normalizes drug names to lowercase.\n",
    "    4. Scans for high-risk keywords (Vasopressors, Sedatives, Opioids) using vectorized regex.\n",
    "    5. Aggregates counts (total meds, distinct meds, high-risk meds) into dictionaries.\n",
    "    6. Converts aggregated dictionaries into a final clean DataFrame.\n",
    "    \n",
    "     Arguments:\n",
    "        emar (pd.DataFrame): The lookup dataframe from load_emar.\n",
    "        detail_path (str): Path to the detailed medication file.\n",
    "        text_col (str): The column name containing drug descriptions.\n",
    "        chunksize (int): Number of rows to process at a time.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A feature matrix with one row per admission, containing\n",
    "                      counts and binary flags for high-risk medication usage.\n",
    "    \"\"\"\n",
    "    # Accumulators\n",
    "    num_admin = defaultdict(int)\n",
    "    distinct_meds = defaultdict(set)\n",
    "    num_high_risk = defaultdict(int)\n",
    "    \n",
    "    has_high_risk = set()\n",
    "    has_vaso = set()\n",
    "    has_sed = set()\n",
    "    has_opioid = set()\n",
    "    \n",
    "    # Compile regex patterns\n",
    "    pat_high = \"|\".join(HIGH_RISK_MED_KEYWORDS)\n",
    "    pat_vaso = \"|\".join(VASOACTIVE_KEYWORDS)\n",
    "    pat_sed  = \"|\".join(SEDATION_KEYWORDS)\n",
    "    pat_op   = \"|\".join(OPIOID_KEYWORDS)\n",
    "    \n",
    "    # Prepare mapping table \n",
    "    emar_map = emar[[\"emar_id\", \"hadm_id\"]].drop_duplicates()\n",
    "    \n",
    "    chunk_idx = 0\n",
    "    \n",
    "    # Read detail file in chunks\n",
    "    for chunk in pd.read_csv(detail_path, chunksize=chunksize, usecols=[\"emar_id\", text_col], low_memory=False):\n",
    "        chunk_idx += 1\n",
    "        if chunk_idx % 5 == 0:\n",
    "            gc.collect()\n",
    "            \n",
    "        # Merge to attach hadm_id\n",
    "        chunk = chunk.merge(emar_map, on=\"emar_id\", how=\"left\")\n",
    "        chunk = chunk.dropna(subset=[\"hadm_id\"])\n",
    "        \n",
    "        if chunk.empty: continue\n",
    "            \n",
    "        chunk[\"hadm_id\"] = chunk[\"hadm_id\"].astype(int)\n",
    "        chunk[\"text\"] = chunk[text_col].astype(str).str.lower()\n",
    "        \n",
    "        # Count admins\n",
    "        counts = chunk[\"hadm_id\"].value_counts()\n",
    "        for hadm, count in counts.items():\n",
    "            num_admin[hadm] += count\n",
    "            \n",
    "        # Distinct meds (store in set)\n",
    "        for hadm, grp in chunk.groupby(\"hadm_id\")[\"text\"]:\n",
    "            distinct_meds[hadm].update(grp.unique())\n",
    "            \n",
    "        # High Risk Checks (Vectorized)\n",
    "        mask_high = chunk[\"text\"].str.contains(pat_high, na=False)\n",
    "        if mask_high.any():\n",
    "            high_chunk = chunk[mask_high]\n",
    "            \n",
    "            # Counts\n",
    "            h_counts = high_chunk[\"hadm_id\"].value_counts()\n",
    "            for hadm, count in h_counts.items():\n",
    "                num_high_risk[hadm] += count\n",
    "            \n",
    "            # Flags\n",
    "            has_high_risk.update(high_chunk[\"hadm_id\"].unique())\n",
    "            \n",
    "            # Sub-flags (only check rows that are already high risk)\n",
    "            if pat_vaso:\n",
    "                ids = high_chunk.loc[high_chunk[\"text\"].str.contains(pat_vaso, na=False), \"hadm_id\"]\n",
    "                has_vaso.update(ids.unique())\n",
    "            \n",
    "            if pat_sed:\n",
    "                ids = high_chunk.loc[high_chunk[\"text\"].str.contains(pat_sed, na=False), \"hadm_id\"]\n",
    "                has_sed.update(ids.unique())\n",
    "                \n",
    "            if pat_op:\n",
    "                ids = high_chunk.loc[high_chunk[\"text\"].str.contains(pat_op, na=False), \"hadm_id\"]\n",
    "                has_opioid.update(ids.unique())\n",
    "\n",
    "    # Build Result DataFrame\n",
    "    all_ids = set(num_admin.keys())\n",
    "    \n",
    "    feat = pd.DataFrame({\"hadm_id\": list(all_ids)})\n",
    "    feat[\"hadm_id\"] = feat[\"hadm_id\"].astype(\"Int64\")\n",
    "    feat = feat.set_index(\"hadm_id\")\n",
    "    \n",
    "    # Map accumulated values\n",
    "    feat[\"num_meds_admin\"] = feat.index.map(num_admin).fillna(0).astype(int)\n",
    "    feat[\"num_distinct_meds\"] = feat.index.map(lambda x: len(distinct_meds.get(x, set()))).astype(int)\n",
    "    feat[\"num_high_risk_meds\"] = feat.index.map(num_high_risk).fillna(0).astype(int)\n",
    "    \n",
    "    # Flags\n",
    "    feat[\"has_high_risk_med\"] = feat.index.isin(has_high_risk).astype(int)\n",
    "    feat[\"has_vasoactive_med\"] = feat.index.isin(has_vaso).astype(int)\n",
    "    feat[\"has_sedation_med\"] = feat.index.isin(has_sed).astype(int)\n",
    "    feat[\"has_opioid_med\"] = feat.index.isin(has_opioid).astype(int)\n",
    "    \n",
    "    feat = feat.reset_index()\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa87fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute \n",
    "if __name__ == \"__main__\":\n",
    "    emar_map = load_emar(EMAR_PATH)\n",
    "    text_col = detect_emar_detail_text_col(EMAR_DETAIL_PATH)\n",
    "    feat_df = build_emar_features_chunked(emar_map, EMAR_DETAIL_PATH, text_col, CHUNKSIZE)\n",
    "    print(f\"Saving {len(feat_df)} rows to {OUTPUT_PATH}\")\n",
    "    feat_df.to_csv(OUTPUT_PATH, index=False)\n",
    "    print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
